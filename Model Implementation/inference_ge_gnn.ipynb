{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axWZ_Cla2CIQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97e60884",
        "outputId": "d824eb52-dde5-4bde-b704-c713d51baa93"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78756bfc"
      },
      "source": [
        "Now you can load your data from Google Drive. Replace `\"path/to/your/data.csv\"` with the actual path to your file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy scikit-learn pyyaml\n",
        "!nvidia-smi\n",
        "!pip install torch==2.4.1+cu124 torchvision==0.19.1+cu124 torchaudio==2.4.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n",
        "import dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cw1RAR1m4WwH",
        "outputId": "984b187a-20fa-4d2a-90e5-8fa5232090be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Sun Nov  9 08:45:13 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   37C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.4.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.4.1%2Bcu124-cp312-cp312-linux_x86_64.whl (797.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.19.1%2Bcu124-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m154.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.1%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1+cu124) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.99 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (24.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.99 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.4/883.4 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.99 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m145.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.2.65 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.2.65-py3-none-manylinux2014_x86_64.whl (363.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.0.44 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.0.44-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.119 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.119-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.0.99 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.0.99-py3-none-manylinux2014_x86_64.whl (128.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.0.142 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.0.142-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.99 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.99 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1+cu124) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1+cu124) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.1+cu124) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.1+cu124) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.4.2.65 nvidia-cuda-cupti-cu12-12.4.99 nvidia-cuda-nvrtc-cu12-12.4.99 nvidia-cuda-runtime-cu12-12.4.99 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.0.44 nvidia-curand-cu12-10.3.5.119 nvidia-cusolver-cu12-11.6.0.99 nvidia-cusparse-cu12-12.3.0.142 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.4.99 torch-2.4.1+cu124 torchaudio-2.4.1+cu124 torchvision-0.19.1+cu124 triton-3.0.0\n",
            "2.4.1+cu124\n",
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/torch-2.4/cu124/dgl-2.4.0%2Bcu124-cp312-cp312-manylinux1_x86_64.whl (347.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.12/dist-packages (from dgl) (3.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from dgl) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from dgl) (25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dgl) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from dgl) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from dgl) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from dgl) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from dgl) (4.67.1)\n",
            "Collecting torch<=2.4.0 (from dgl)\n",
            "  Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dgl) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dgl) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dgl) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->dgl) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->dgl) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->dgl) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->dgl) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.4.99)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->dgl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->dgl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->dgl) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m150.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, dgl\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.99\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.99:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.99\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.0.142\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.0.142:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.0.142\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.119\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.119:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.119\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.0.44\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.0.44:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.0.44\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.99\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.99:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.99\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.99\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.99:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.99\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.99\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.99:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.99\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.2.65\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.2.65:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.2.65\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.0.99\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.0.99:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.0.99\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu124\n",
            "    Uninstalling torch-2.4.1+cu124:\n",
            "      Successfully uninstalled torch-2.4.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.1+cu124 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.19.1+cu124 requires torch==2.4.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dgl-2.4.0+cu124 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "cad8047709f646eda50a2a276cfc1263"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c73c0b0d"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# file_path = ''  # Replace with your file path\n",
        "# try:\n",
        "#     df = pd.read_csv(file_path)\n",
        "#     display(df.head())\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: File not found at {file_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41U1zOyx4PBY",
        "outputId": "3c75f553-135a-4316-ef20-b9e6280e09bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.0.2)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (1.16.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.9.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# GE-GNN — Inference Script\n",
        "# (checkpoint-compatible)\n",
        "# =========================\n",
        "\n",
        "import os, sys, copy, yaml, argparse, warnings, ast, time\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import scipy.io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "import category_encoders as ce\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# -----------------------\n",
        "# 0) Paths & Config\n",
        "# -----------------------\n",
        "CONFIG_PATH = \"/content/drive/MyDrive/GE-GNN/config/amazon.yaml\"\n",
        "NEW_CSV     = \"/content/drive/MyDrive/GE-GNN/MY_work/DataSets/sports_test_inference.csv\" # This path is for inference only, not evaluation\n",
        "MODEL_PATH  = \"/content/drive/MyDrive/GE-GNN/result/sports_outdoors_20k_F_model_head4.pt\"\n",
        "OUT_DIR     = \"/content/drive/MyDrive/GE-GNN/result\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# -----------------------\n",
        "# 1) Load config + device\n",
        "# -----------------------\n",
        "with open(CONFIG_PATH, \"r\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "args = argparse.Namespace(**cfg)\n",
        "\n",
        "# Device resolution (allow int or \"cuda:x\" in yaml)\n",
        "if isinstance(args.cuda, int):\n",
        "    cuda_idx = args.cuda\n",
        "elif isinstance(args.cuda, str) and args.cuda.isdigit():\n",
        "    cuda_idx = int(args.cuda)\n",
        "else:\n",
        "    try:\n",
        "        cuda_idx = int(str(args.cuda).split(\":\")[-1])\n",
        "    except Exception:\n",
        "        cuda_idx = 0\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    if cuda_idx >= torch.cuda.device_count():\n",
        "        print(f\"CUDA index {cuda_idx} out of range. Using cuda:0\")\n",
        "        cuda_idx = 0\n",
        "    device = torch.device(f\"cuda:{cuda_idx}\")\n",
        "    torch.cuda.set_device(cuda_idx)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"--- Using device:\", device)\n",
        "\n",
        "# -----------------------\n",
        "# 2) Load new CSV\n",
        "# -----------------------\n",
        "print(\"\\n--- Loading new data for inference ---\")\n",
        "# Load the evaluation data with labels instead of the inference data without labels\n",
        "EVAL_CSV = \"/content/drive/MyDrive/GE-GNN/DataSets/Kaggle_Amazon_Reviews_CSV/Cell_Phones_and_Accessories_50k.csv\"\n",
        "df = pd.read_csv(EVAL_CSV)\n",
        "print(f\"Loaded {len(df)} rows from:\\n{EVAL_CSV}\")\n",
        "\n",
        "\n",
        "df_orig = df.copy() # Keep original for output, includes 'class'\n",
        "\n",
        "# Ensure columns exist\n",
        "for col in [\"helpful\", \"reviewTime\", \"reviewerID\", \"reviewText\", \"summary\", \"reviewerName\", \"asin\", \"overall\", \"class\"]: # Added 'class' here\n",
        "    if col not in df.columns:\n",
        "        raise RuntimeError(f\"Required column missing in CSV: {col}\")\n",
        "\n",
        "# helpful → safe parse\n",
        "def _safe_list(x):\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if isinstance(x, str):\n",
        "        try:\n",
        "            return ast.literal_eval(x)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return [0, 0]\n",
        "\n",
        "df[\"helpful\"] = df[\"helpful\"].apply(_safe_list)\n",
        "df[\"helpful_votes\"]   = df[\"helpful\"].apply(lambda x: int(x[0]) if len(x)>=1 else 0)\n",
        "df[\"unhelpful_votes\"] = df[\"helpful\"].apply(lambda x: int(x[1]) if len(x)>=2 else 0)\n",
        "df[\"total_votes\"] = df[\"helpful_votes\"] + df[\"unhelpful_votes\"]\n",
        "df[\"helpful_unhelpful_ratio\"] = df.apply(\n",
        "    lambda r: (r[\"helpful_votes\"] / r[\"total_votes\"]) if r[\"total_votes\"]>0 else 0.0, axis=1\n",
        ")\n",
        "\n",
        "# Dates & gaps\n",
        "df[\"reviewTime_dt\"] = pd.to_datetime(df[\"reviewTime\"], format=\"%m %d, %Y\", errors=\"coerce\")\n",
        "df_sorted = df.sort_values(by=[\"reviewerID\", \"reviewTime_dt\"])\n",
        "df_sorted[\"prev_reviewTime_dt\"] = df_sorted.groupby(\"reviewerID\")[\"reviewTime_dt\"].shift(1)\n",
        "df_sorted[\"day_gap\"] = (df_sorted[\"reviewTime_dt\"] - df_sorted[\"prev_reviewTime_dt\"]).dt.days.fillna(0)\n",
        "\n",
        "# restore row order and attach day_gap\n",
        "df = df.loc[df_sorted.index].copy()\n",
        "df[\"day_gap\"] = df_sorted[\"day_gap\"].astype(int)\n",
        "df[\"same_day_indicator\"] = (df[\"day_gap\"] == 0).astype(int)\n",
        "\n",
        "# totals by reviewer\n",
        "df[\"reviewerID\"] = df[\"reviewerID\"].astype(str)\n",
        "df[\"total_helpful_votes\"]   = df.groupby(\"reviewerID\")[\"helpful_votes\"].transform(\"sum\")\n",
        "df[\"total_unhelpful_votes\"] = df.groupby(\"reviewerID\")[\"unhelpful_votes\"].transform(\"sum\")\n",
        "\n",
        "# word count\n",
        "df[\"review_word_count\"] = df[\"reviewText\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# sentiment\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except LookupError:\n",
        "    nltk.download('vader_lexicon')\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "df[\"sentiment_score\"] = df[\"reviewText\"].apply(lambda x: analyzer.polarity_scores(str(x))[\"compound\"])\n",
        "\n",
        "# text nulls\n",
        "df[\"reviewText\"]   = df[\"reviewText\"].fillna(\"\")\n",
        "df[\"summary\"]      = df[\"summary\"].fillna(\"\")\n",
        "df[\"reviewerName\"] = df[\"reviewerName\"].fillna(\"\")\n",
        "\n",
        "# TFIDF + SVD (same dims used earlier)\n",
        "tfidf_review = TfidfVectorizer(max_features=5000)\n",
        "svd_review   = TruncatedSVD(n_components=7, random_state=42)\n",
        "review_svd   = svd_review.fit_transform(tfidf_review.fit_transform(df[\"reviewText\"]))\n",
        "review_svd_df = pd.DataFrame(review_svd, columns=[f\"review_text_svd_{i}\" for i in range(review_svd.shape[1])])\n",
        "\n",
        "tfidf_sum = TfidfVectorizer(max_features=2000)\n",
        "svd_sum   = TruncatedSVD(n_components=3, random_state=42)\n",
        "sum_svd   = svd_sum.fit_transform(tfidf_sum.fit_transform(df[\"summary\"]))\n",
        "sum_svd_df = pd.DataFrame(sum_svd, columns=[f\"summary_svd_{i}\" for i in range(sum_svd.shape[1])])\n",
        "\n",
        "# Frequency encoding (re-fit for inference set — matches your previous approach)\n",
        "enc_reviewer = ce.CountEncoder(cols=[\"reviewerID\"])\n",
        "enc_asin     = ce.CountEncoder(cols=[\"asin\"])\n",
        "enc_rname    = ce.CountEncoder(cols=[\"reviewerName\"])\n",
        "\n",
        "rev_enc  = enc_reviewer.fit_transform(df[\"reviewerID\"]).rename(columns={\"reviewerID\": \"reviewerID_encoded\"})\n",
        "asin_enc = enc_asin.fit_transform(df[\"asin\"]).rename(columns={\"asin\": \"asin_encoded\"})\n",
        "rnm_enc  = enc_rname.fit_transform(df[\"reviewerName\"]).rename(columns={\"reviewerName\": \"reviewerName_encoded\"})\n",
        "\n",
        "num_feats = df[[\n",
        "    \"overall\",\"helpful_votes\",\"unhelpful_votes\",\"helpful_unhelpful_ratio\",\n",
        "    \"day_gap\",\"same_day_indicator\",\"review_word_count\",\"sentiment_score\",\n",
        "    \"total_helpful_votes\",\"total_unhelpful_votes\",\"total_votes\"\n",
        "]]\n",
        "\n",
        "X = pd.concat([\n",
        "    num_feats.reset_index(drop=True),\n",
        "    review_svd_df.reset_index(drop=True),\n",
        "    sum_svd_df.reset_index(drop=True),\n",
        "    rev_enc.reset_index(drop=True),\n",
        "    asin_enc.reset_index(drop=True),\n",
        "    rnm_enc.reset_index(drop=True),\n",
        "], axis=1).astype(np.float32)\n",
        "\n",
        "print(\"Feature engineering complete.\")\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 3) Build heterograph: ('r','p','r'), ('r','s','r'), ('r','v','r')\n",
        "# ---------------------------------------------------\n",
        "N = len(df)\n",
        "idx_map = {old: i for i, old in enumerate(df.index)}\n",
        "\n",
        "upu_src, upu_dst = [], []\n",
        "usu_src, usu_dst = [], []\n",
        "uvu_src, uvu_dst = [], []\n",
        "\n",
        "# same product (asin) → 'p'\n",
        "for asin, g in df.groupby(\"asin\"):\n",
        "    nodes = [idx_map[i] for i in g.index.tolist()]\n",
        "    if len(nodes) > 1:\n",
        "        for i in range(len(nodes)):\n",
        "            for j in range(len(nodes)):\n",
        "                if i != j:\n",
        "                    upu_src.append(nodes[i]); upu_dst.append(nodes[j])\n",
        "\n",
        "# same user constraints\n",
        "for uid, g in df.groupby(\"reviewerID\"):\n",
        "    rows = g.index.tolist()\n",
        "    for i in range(len(rows)):\n",
        "        for j in range(len(rows)):\n",
        "            if i == j:\n",
        "                continue\n",
        "            i0, j0 = rows[i], rows[j]\n",
        "            a = idx_map[i0]; b = idx_map[j0]\n",
        "            # U-S-U: same star rating == simplistic sentiment proxy used during training\n",
        "            if df.loc[i0, \"overall\"] == df.loc[j0, \"overall\"]:\n",
        "                usu_src.append(a); usu_dst.append(b)\n",
        "            # U-V-U: similar length (<=10 words)\n",
        "            if abs(df.loc[i0, \"review_word_count\"] - df.loc[j0, \"review_word_count\"]) <= 10:\n",
        "                uvu_src.append(a); uvu_dst.append(b)\n",
        "\n",
        "# tensors\n",
        "upu_src = torch.tensor(upu_src, dtype=torch.int32)\n",
        "upu_dst = torch.tensor(upu_dst, dtype=torch.int32)\n",
        "usu_src = torch.tensor(usu_src, dtype=torch.int32)\n",
        "usu_dst = torch.tensor(usu_dst, dtype=torch.int32)\n",
        "uvu_src = torch.tensor(uvu_src, dtype=torch.int32)\n",
        "uvu_dst = torch.tensor(uvu_dst, dtype=torch.int32)\n",
        "\n",
        "graph_data = {\n",
        "    (\"r\",\"p\",\"r\"): (upu_src, upu_dst),\n",
        "    (\"r\",\"s\",\"r\"): (usu_src, usu_dst),\n",
        "    (\"r\",\"v\",\"r\"): (uvu_src, uvu_dst),\n",
        "}\n",
        "g = dgl.heterograph(graph_data, num_nodes_dict={\"r\": N})\n",
        "g.nodes[\"r\"].data[\"feat\"] = torch.from_numpy(X.values).float()\n",
        "\n",
        "for et in g.etypes:\n",
        "    g = dgl.add_self_loop(g, etype=et)\n",
        "\n",
        "g = g.to(device)\n",
        "g.nodes[\"r\"].data[\"feat\"] = g.nodes[\"r\"].data[\"feat\"].to(device)\n",
        "\n",
        "if SAVE_INTERMEDIATE:\n",
        "    dgl_path = os.path.join(OUT_DIR, \"evaluation_data.dgl\")\n",
        "    dgl.save_graphs(dgl_path, g)\n",
        "    print(f\"Saved inference DGL graph to: {dgl_path}\")\n",
        "\n",
        "# --------------------------------\n",
        "# 4) Model (checkpoint-compatible names!)\n",
        "# --------------------------------\n",
        "class RelationAware_Compat(nn.Module):\n",
        "    # name path in ckpt: rel_aware.d_lin.*\n",
        "    def __init__(self, input_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.d_lin = nn.Linear(input_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src, dst):\n",
        "        src = self.d_lin(src)\n",
        "        dst = self.d_lin(dst)\n",
        "        diff = src - dst\n",
        "        return self.tanh(src + dst + diff)\n",
        "\n",
        "class HLayer_Compat(nn.Module):\n",
        "    # keys in ckpt: blocks.<etype>.[0|1].(…)\n",
        "    # this block uses w_linear, relation_aware, atten\n",
        "    def __init__(self, input_dim, output_dim, head, rel_aware, etype, dropout, if_sum=False):\n",
        "        super().__init__()\n",
        "        self.etype = etype\n",
        "        self.head  = head\n",
        "        self.hd    = output_dim\n",
        "        self.if_sum = if_sum\n",
        "\n",
        "        self.atten = nn.Linear(3*output_dim, 1)\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.w_linear = nn.Linear(input_dim, output_dim*head)\n",
        "        self.relation_aware = rel_aware\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            # store original features for edge sign\n",
        "            g.nodes[\"r\"].data[\"feat\"] = h\n",
        "            # edge relation score\n",
        "            g.apply_edges(self.sign_edges, etype=self.etype)\n",
        "            # projection\n",
        "            h_proj = self.w_linear(h)\n",
        "            g.nodes[\"r\"].data[\"h\"] = h_proj\n",
        "            # message passing on this etype\n",
        "            g.update_all(self.message, self.reduce, etype=self.etype)\n",
        "            out = g.nodes[\"r\"].data[\"out\"]\n",
        "            edge_s = g.nodes[\"r\"].data[\"s\"]\n",
        "            if not self.if_sum:\n",
        "                return edge_s, out, h_proj.view(-1, self.head*self.hd)\n",
        "            else:\n",
        "                return edge_s, out, h_proj.view(-1, self.head, self.hd).sum(-2)\n",
        "\n",
        "    def message(self, edges):\n",
        "        src_f  = edges.src[\"h\"].view(-1, self.head, self.hd)\n",
        "        dst_f  = edges.dst[\"h\"].view(-1, self.head, self.hd)\n",
        "        edge_s = edges.data[\"edge_sum\"].view(-1, self.head, self.hd)\n",
        "        z = torch.cat([src_f, dst_f, edge_s], dim=-1)\n",
        "        alpha = self.atten(z)\n",
        "        alpha = self.leakyrelu(alpha)\n",
        "        return {\"atten\": alpha, \"sf\": src_f, \"edge_s\": edge_s}\n",
        "\n",
        "    def reduce(self, nodes):\n",
        "        alpha = nodes.mailbox[\"atten\"]\n",
        "        sf    = nodes.mailbox[\"sf\"]\n",
        "        alpha = self.softmax(alpha)\n",
        "        out = torch.sum(alpha * sf, dim=1)  # (N, head, hd)\n",
        "        if not self.if_sum:\n",
        "            out = out.view(-1, self.head*self.hd)\n",
        "            edge_s = torch.mean(nodes.mailbox[\"edge_s\"], dim=1).view(-1, self.head*self.hd)\n",
        "            return {\"out\": out, \"s\": edge_s}\n",
        "        else:\n",
        "            out = out.sum(dim=-2)\n",
        "            edge_s = torch.sum(torch.mean(nodes.mailbox[\"edge_s\"], dim=1), dim=-2)\n",
        "            return {\"out\": out, \"s\": edge_s}\n",
        "\n",
        "    def sign_edges(self, edges):\n",
        "        src = edges.src[\"feat\"]\n",
        "        dst = edges.dst[\"feat\"]\n",
        "        edge_sum = self.relation_aware(src, dst)\n",
        "        return {\"edge_sum\": edge_sum}\n",
        "\n",
        "class Gate_Compat(nn.Module):\n",
        "    def __init__(self, head, output_dim, dropout, if_sum=False):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.head = head\n",
        "        if not if_sum:\n",
        "            self.beta = nn.Parameter(torch.empty(2*head*output_dim, 1))\n",
        "        else:\n",
        "            self.beta = nn.Parameter(torch.empty(2*output_dim, 1))\n",
        "        nn.init.xavier_normal_(self.beta, gain=1.414)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, edge_sum, out, h):\n",
        "        beta = torch.cat([edge_sum, out], dim=1)\n",
        "        gate = self.sigmoid(beta @ self.beta)\n",
        "        return gate * out + (1 - gate) * h\n",
        "\n",
        "class MultiRelationGELayer_Compat(nn.Module):\n",
        "    # ckpt names: layers.X.lin, layers.X.rel_aware, layers.X.blocks[etype][0/1]\n",
        "    def __init__(self, input_dim, output_dim, head, graph, dropout, if_sum=False):\n",
        "        super().__init__()\n",
        "        rels = list(graph.etypes)\n",
        "        if \"homo\" in rels:\n",
        "            rels.remove(\"homo\")\n",
        "        self.relations = rels\n",
        "        self.if_sum = if_sum\n",
        "\n",
        "        self.rel_aware = RelationAware_Compat(input_dim, output_dim*head, dropout)\n",
        "        if not if_sum:\n",
        "            self.lin = nn.Linear(len(self.relations)*output_dim*head, output_dim*head)\n",
        "        else:\n",
        "            self.lin = nn.Linear(len(self.relations)*output_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.blocks = nn.ModuleDict()\n",
        "        for e in self.relations:\n",
        "            seq = nn.ModuleList()\n",
        "            seq.append(HLayer_Compat(input_dim, output_dim, head, self.rel_aware, e, dropout, if_sum))\n",
        "            seq.append(Gate_Compat(head, output_dim, dropout, if_sum))\n",
        "            self.blocks[e] = seq\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        outs = []\n",
        "        for e, seq in self.blocks.items():\n",
        "            edge_s, out, h_proj = seq[0](g, h)\n",
        "            he = seq[1](edge_s, out, h_proj)\n",
        "            outs.append(he)\n",
        "        x = torch.cat(outs, dim=1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "class GE_GNN_Compat(nn.Module):\n",
        "    # ckpt top-level list name: layers\n",
        "    def __init__(self, args, g):\n",
        "        super().__init__()\n",
        "        # detect input dim\n",
        "        if \"r\" in g.ntypes and \"feat\" in g.nodes[\"r\"].data:\n",
        "            in_dim = g.nodes[\"r\"].data[\"feat\"].shape[1]\n",
        "        elif \"feature\" in g.ndata:\n",
        "            in_dim = g.ndata[\"feature\"].shape[1]\n",
        "        else:\n",
        "            raise RuntimeError(\"No node features found ('feat' or 'feature').\")\n",
        "        self.layers = nn.ModuleList()\n",
        "        if args.n_layer == 1:\n",
        "            self.layers.append(MultiRelationGELayer_Compat(in_dim, args.n_class, args.head, g, args.dropout, if_sum=True))\n",
        "        else:\n",
        "            self.layers.append(MultiRelationGELayer_Compat(in_dim, args.intra_dim, args.head, g, args.dropout, if_sum=False))\n",
        "            for _ in range(1, args.n_layer-1):\n",
        "                self.layers.append(MultiRelationGELayer_Compat(args.intra_dim*args.head, args.intra_dim, args.head, g, args.dropout, if_sum=False))\n",
        "            self.layers.append(MultiRelationGELayer_Compat(args.intra_dim*args.head, args.n_class, args.head, g, args.dropout, if_sum=True))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(args.dropout)\n",
        "\n",
        "    def forward(self, g):\n",
        "        if \"r\" in g.ntypes and \"feat\" in g.nodes[\"r\"].data:\n",
        "            h = g.nodes[\"r\"].data[\"feat\"].float()\n",
        "        elif \"feature\" in g.ndata:\n",
        "            h = g.ndata[\"feature\"].float()\n",
        "        else:\n",
        "            raise RuntimeError(\"Missing features for forward.\")\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer(g, h)\n",
        "            if i < len(self.layers) - 1:\n",
        "                h = self.relu(h)\n",
        "                h = self.drop(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 5) Load model + state_dict strictly\n",
        "# ---------------------------------------------------\n",
        "print(\"\\n--- Loading model ---\")\n",
        "model = GE_GNN_Compat(args, g).to(device)\n",
        "state = torch.load(MODEL_PATH, map_location=device)\n",
        "# Use strict=False here to see *all* missing/unexpected keys first.\n",
        "missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "\n",
        "# If there are mismatches, print for visibility\n",
        "if len(unexpected) > 0 or len(missing) > 0:\n",
        "    print(\"Note: non-strict load due to mismatches.\")\n",
        "    if len(missing) > 0:\n",
        "        print(\"Missing keys:\", missing)\n",
        "    if len(unexpected) > 0:\n",
        "        print(\"Unexpected keys:\", unexpected)\n",
        "else:\n",
        "    print(\"Model loaded successfully (strict=True would have worked).\")\n",
        "\n",
        "\n",
        "model.eval()\n",
        "print(\"Model ready.\")\n",
        "\n",
        "# --------------------------------\n",
        "# 6) Inference\n",
        "# --------------------------------\n",
        "with torch.no_grad():\n",
        "    logits = model(g)                     # (N, n_class)\n",
        "    probs  = F.softmax(logits, dim=1)     # (N, n_class)\n",
        "    fraud_prob = probs[:,1].detach().cpu().numpy()\n",
        "    pred_cls   = logits.argmax(1).detach().cpu().numpy()\n",
        "\n",
        "# --------------------------------\n",
        "# 7) Export Predictions\n",
        "# --------------------------------\n",
        "df_out = df_orig.copy() # Start with the original dataframe that includes 'class'\n",
        "df_out['predicted_fraud_class'] = pred_cls\n",
        "df_out['fraud_probability']     = fraud_prob\n",
        "# Keep the original 'class' column as is, no need to rename to 'label'\n",
        "\n",
        "print(\"\\nSample predictions:\")\n",
        "print(df_out[['reviewerID','asin','overall','predicted_fraud_class','fraud_probability', 'class']].head(10))\n",
        "\n",
        "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUT_CSV = os.path.join(OUT_DIR, f\"evaluation_predictions_{stamp}.csv\")\n",
        "df_out.to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\n✅ Inference complete. Predictions saved to:\\n{OUT_CSV}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPeiohpB4Fsp",
        "outputId": "fe80a972-6521-44f8-cb9b-d83559c4562e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Using device: cuda:0\n",
            "\n",
            "--- Loading new data for inference ---\n",
            "Loaded 100000 rows from:\n",
            "/content/drive/MyDrive/GE-GNN/DataSets/Kaggle_Amazon_Reviews_CSV/Cell_Phones_and_Accessories_50k.csv\n",
            "Feature engineering complete.\n",
            "Feature matrix shape: (100000, 24)\n",
            "\n",
            "--- Loading model ---\n",
            "Model loaded successfully (strict=True would have worked).\n",
            "Model ready.\n",
            "\n",
            "Sample predictions:\n",
            "       reviewerID        asin  overall  predicted_fraud_class  \\\n",
            "0  A1ZKFGF1OJAC2L  B005AOKW8Q      3.0                      1   \n",
            "1  A1GGBZT79BE9VB  B006ECNCMG      1.0                      1   \n",
            "2  A2MBQUAQT2B3J6  B00GTGETFG      4.0                      0   \n",
            "3  A101MJE2PP14IX  B0062F2AQ4      2.0                      1   \n",
            "4  A1SWJHGNJ50BBJ  B00FUXV6QO      1.0                      1   \n",
            "5  A2P3Z35R396ZKL  B00ATWR0L6      3.0                      1   \n",
            "6   AYZLKZ40XI1YS  B00CFVNXTC      1.0                      0   \n",
            "7  A13NWKT7VUXSG7  B00B9OTEVM      3.0                      0   \n",
            "8  A22R6VF3GAKA0Q  B003UVM2UC      2.0                      0   \n",
            "9  A3HOIB0SJ8E4PE  B00DZQLE3S      1.0                      1   \n",
            "\n",
            "   fraud_probability  class  \n",
            "0       1.000000e+00    0.0  \n",
            "1       1.000000e+00    0.0  \n",
            "2       9.274278e-16    1.0  \n",
            "3       9.766490e-01    0.0  \n",
            "4       1.000000e+00    0.0  \n",
            "5       1.000000e+00    0.0  \n",
            "6       3.147264e-06    0.0  \n",
            "7       2.427637e-09    0.0  \n",
            "8       7.417924e-14    0.0  \n",
            "9       1.000000e+00    0.0  \n",
            "\n",
            "✅ Inference complete. Predictions saved to:\n",
            "/content/drive/MyDrive/GE-GNN/result/evaluation_predictions_20251109_101345.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# GE-GNN — FULL Inference Pipeline\n",
        "# (checkpoint & encoder-compatible)\n",
        "# =========================\n",
        "\n",
        "import os, sys, copy, yaml, argparse, warnings, ast, time, pickle, json\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import scipy.io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix\n",
        ")\n",
        "\n",
        "import category_encoders as ce\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# -----------------------\n",
        "# 0) Paths & Config\n",
        "# -----------------------\n",
        "CONFIG_PATH   = \"/content/drive/MyDrive/GE-GNN/config/amazon.yaml\"\n",
        "# Use a file that HAS labels to get metrics; if not, it will just run inference\n",
        "EVAL_CSV      = \"/content/drive/MyDrive/GE-GNN/MY_work/DataSets/sports_test_inference.csv\"\n",
        "MODEL_PATH    = \"/content/drive/MyDrive/GE-GNN/result/sports_outdoors_20k_F_model_head4.pt\"\n",
        "OUT_DIR       = \"/content/drive/MyDrive/GE-GNN/result\"\n",
        "ARTIFACT_DIR  = \"/content/drive/MyDrive/GE-GNN/artifacts\"   # <— new: where encoders/mappings live\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "\n",
        "# Filenames for artifacts\n",
        "TFIDF_REVIEW_PKL   = os.path.join(ARTIFACT_DIR, \"tfidf_review.pkl\")\n",
        "SVD_REVIEW_PKL     = os.path.join(ARTIFACT_DIR, \"svd_review.pkl\")\n",
        "TFIDF_SUMMARY_PKL  = os.path.join(ARTIFACT_DIR, \"tfidf_summary.pkl\")\n",
        "SVD_SUMMARY_PKL    = os.path.join(ARTIFACT_DIR, \"svd_summary.pkl\")\n",
        "\n",
        "ENC_REVIEWER_PKL   = os.path.join(ARTIFACT_DIR, \"countenc_reviewerID.pkl\")\n",
        "ENC_ASIN_PKL       = os.path.join(ARTIFACT_DIR, \"countenc_asin.pkl\")\n",
        "ENC_RNAME_PKL      = os.path.join(ARTIFACT_DIR, \"countenc_reviewerName.pkl\")\n",
        "\n",
        "# Optional ID maps (not required for inference graph, but saved for reproducibility)\n",
        "REVIEWER_MAP_JSON  = os.path.join(ARTIFACT_DIR, \"reviewerID_to_index.json\")\n",
        "ASIN_MAP_JSON      = os.path.join(ARTIFACT_DIR, \"asin_to_index.json\")\n",
        "\n",
        "# Behavior: if artifacts are missing, fit encoders on current data and save\n",
        "SAVE_ARTIFACTS_IF_MISSING = True\n",
        "\n",
        "# -----------------------\n",
        "# 1) Load config + device\n",
        "# -----------------------\n",
        "with open(CONFIG_PATH, \"r\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "args = argparse.Namespace(**cfg)\n",
        "\n",
        "# Device resolution (allow int or \"cuda:x\" in yaml)\n",
        "if isinstance(args.cuda, int):\n",
        "    cuda_idx = args.cuda\n",
        "elif isinstance(args.cuda, str) and args.cuda.isdigit():\n",
        "    cuda_idx = int(args.cuda)\n",
        "else:\n",
        "    try:\n",
        "        cuda_idx = int(str(args.cuda).split(\":\")[-1])\n",
        "    except Exception:\n",
        "        cuda_idx = 0\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    if cuda_idx >= torch.cuda.device_count():\n",
        "        print(f\"CUDA index {cuda_idx} out of range. Using cuda:0\")\n",
        "        cuda_idx = 0\n",
        "    device = torch.device(f\"cuda:{cuda_idx}\")\n",
        "    torch.cuda.set_device(cuda_idx)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"--- Using device:\", device)\n",
        "\n",
        "# -----------------------\n",
        "# 2) Load CSV & FE\n",
        "# -----------------------\n",
        "print(\"\\n--- Loading new data for inference ---\")\n",
        "df = pd.read_csv(EVAL_CSV)\n",
        "print(f\"Loaded {len(df)} rows from:\\n{EVAL_CSV}\")\n",
        "\n",
        "df_orig = df.copy()  # keep the original, may include 'class'\n",
        "\n",
        "# Ensure required columns exist (class is optional)\n",
        "needed = [\"helpful\", \"reviewTime\", \"reviewerID\", \"reviewText\", \"summary\", \"reviewerName\", \"asin\", \"overall\"]\n",
        "missing = [c for c in needed if c not in df.columns]\n",
        "if missing:\n",
        "    raise RuntimeError(f\"Required column(s) missing in CSV: {missing}\")\n",
        "\n",
        "# parse helpful safely\n",
        "def _safe_list(x):\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if isinstance(x, str):\n",
        "        try:\n",
        "            return ast.literal_eval(x)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return [0, 0]\n",
        "\n",
        "df[\"helpful\"] = df[\"helpful\"].apply(_safe_list)\n",
        "df[\"helpful_votes\"]   = df[\"helpful\"].apply(lambda x: int(x[0]) if len(x)>=1 else 0)\n",
        "df[\"unhelpful_votes\"] = df[\"helpful\"].apply(lambda x: int(x[1]) if len(x)>=2 else 0)\n",
        "df[\"total_votes\"] = df[\"helpful_votes\"] + df[\"unhelpful_votes\"]\n",
        "df[\"helpful_unhelpful_ratio\"] = df.apply(\n",
        "    lambda r: (r[\"helpful_votes\"] / r[\"total_votes\"]) if r[\"total_votes\"]>0 else 0.0, axis=1\n",
        ")\n",
        "\n",
        "# time features\n",
        "df[\"reviewTime_dt\"] = pd.to_datetime(df[\"reviewTime\"], format=\"%m %d, %Y\", errors=\"coerce\")\n",
        "df_sorted = df.sort_values(by=[\"reviewerID\", \"reviewTime_dt\"])\n",
        "df_sorted[\"prev_reviewTime_dt\"] = df_sorted.groupby(\"reviewerID\")[\"reviewTime_dt\"].shift(1)\n",
        "df_sorted[\"day_gap\"] = (df_sorted[\"reviewTime_dt\"] - df_sorted[\"prev_reviewTime_dt\"]).dt.days.fillna(0)\n",
        "\n",
        "df = df.loc[df_sorted.index].copy()\n",
        "df[\"day_gap\"] = df_sorted[\"day_gap\"].astype(int)\n",
        "df[\"same_day_indicator\"] = (df[\"day_gap\"] == 0).astype(int)\n",
        "\n",
        "# totals by reviewer\n",
        "df[\"reviewerID\"] = df[\"reviewerID\"].astype(str)\n",
        "df[\"total_helpful_votes\"]   = df.groupby(\"reviewerID\")[\"helpful_votes\"].transform(\"sum\")\n",
        "df[\"total_unhelpful_votes\"] = df.groupby(\"reviewerID\")[\"unhelpful_votes\"].transform(\"sum\")\n",
        "\n",
        "# word count\n",
        "df[\"review_word_count\"] = df[\"reviewText\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# sentiment\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except LookupError:\n",
        "    nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "df[\"sentiment_score\"] = df[\"reviewText\"].apply(lambda x: sid.polarity_scores(str(x))[\"compound\"])\n",
        "\n",
        "# nulls\n",
        "df[\"reviewText\"]   = df[\"reviewText\"].fillna(\"\")\n",
        "df[\"summary\"]      = df[\"summary\"].fillna(\"\")\n",
        "df[\"reviewerName\"] = df[\"reviewerName\"].fillna(\"\")\n",
        "df[\"asin\"]         = df[\"asin\"].astype(str)\n",
        "\n",
        "# -----------------------\n",
        "# 3) Load/fit encoders\n",
        "# -----------------------\n",
        "def load_pickle(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def try_load_or_fit_tfidf_svd(text_series, tfidf_path, svd_path, tfidf_kwargs, svd_kwargs):\n",
        "    \"\"\"Load TFIDF & SVD; if missing and allowed, fit on current data and save.\"\"\"\n",
        "    tfidf = None\n",
        "    svd = None\n",
        "    if os.path.exists(tfidf_path) and os.path.exists(svd_path):\n",
        "        try:\n",
        "            tfidf = load_pickle(tfidf_path)\n",
        "            svd = load_pickle(svd_path)\n",
        "            X = tfidf.transform(text_series)\n",
        "            Xs = svd.transform(X)\n",
        "            return Xs, tfidf, svd, False\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Failed to load TFIDF/SVD from disk ({e}). Will refit.\")\n",
        "    if not SAVE_ARTIFACTS_IF_MISSING:\n",
        "        raise RuntimeError(f\"Missing TFIDF/SVD artifacts: {tfidf_path}, {svd_path}\")\n",
        "    # fit\n",
        "    tfidf = TfidfVectorizer(**tfidf_kwargs)\n",
        "    X = tfidf.fit_transform(text_series)\n",
        "    svd = TruncatedSVD(**svd_kwargs)\n",
        "    Xs = svd.fit_transform(X)\n",
        "    # save\n",
        "    with open(tfidf_path, \"wb\") as f: pickle.dump(tfidf, f)\n",
        "    with open(svd_path, \"wb\") as f:   pickle.dump(svd, f)\n",
        "    return Xs, tfidf, svd, True\n",
        "\n",
        "def try_load_or_fit_countenc(series, pkl_path, colname):\n",
        "    \"\"\"Load CountEncoder; if missing and allowed, fit & save.\"\"\"\n",
        "    enc = None\n",
        "    if os.path.exists(pkl_path):\n",
        "        try:\n",
        "            enc = load_pickle(pkl_path)\n",
        "            # transform expects a DataFrame\n",
        "            out = enc.transform(pd.DataFrame({colname: series}))\n",
        "            return out.rename(columns={colname: f\"{colname}_encoded\"}), enc, False\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Failed to load CountEncoder from disk ({e}). Will refit.\")\n",
        "    if not SAVE_ARTIFACTS_IF_MISSING:\n",
        "        raise RuntimeError(f\"Missing CountEncoder artifact: {pkl_path}\")\n",
        "\n",
        "    enc = ce.CountEncoder(cols=[colname], handle_unknown=0, handle_missing=0)  # handle unseen/missing as 0\n",
        "    out = enc.fit_transform(pd.DataFrame({colname: series}))\n",
        "    # save\n",
        "    with open(pkl_path, \"wb\") as f: pickle.dump(enc, f)\n",
        "    return out.rename(columns={colname: f\"{colname}_encoded\"}), enc, True\n",
        "\n",
        "print(\"\\n--- Loading/Fitting text/vector encoders ---\")\n",
        "review_svd, tfidf_review, svd_review, fitted_review = try_load_or_fit_tfidf_svd(\n",
        "    df[\"reviewText\"],\n",
        "    TFIDF_REVIEW_PKL, SVD_REVIEW_PKL,\n",
        "    tfidf_kwargs=dict(max_features=5000),\n",
        "    svd_kwargs=dict(n_components=7, random_state=42)\n",
        ")\n",
        "summary_svd, tfidf_summary, svd_summary, fitted_summary = try_load_or_fit_tfidf_svd(\n",
        "    df[\"summary\"],\n",
        "    TFIDF_SUMMARY_PKL, SVD_SUMMARY_PKL,\n",
        "    tfidf_kwargs=dict(max_features=2000),\n",
        "    svd_kwargs=dict(n_components=3, random_state=42)\n",
        ")\n",
        "\n",
        "print(\"\\n--- Loading/Fitting categorical encoders ---\")\n",
        "rev_enc_df, enc_reviewer, fitted_rev = try_load_or_fit_countenc(df[\"reviewerID\"], ENC_REVIEWER_PKL, \"reviewerID\")\n",
        "asin_enc_df, enc_asin, fitted_asin = try_load_or_fit_countenc(df[\"asin\"], ENC_ASIN_PKL, \"asin\")\n",
        "rnm_enc_df, enc_rname, fitted_rnm = try_load_or_fit_countenc(df[\"reviewerName\"], ENC_RNAME_PKL, \"reviewerName\")\n",
        "\n",
        "# Optional: save ID -> idx maps for reproducibility (not required for inference graph)\n",
        "try:\n",
        "    if fitted_rev:\n",
        "        rev_ids = pd.Series(df[\"reviewerID\"].unique())\n",
        "        reviewer_map = {k: int(v) for v, k in enumerate(rev_ids)}\n",
        "        with open(REVIEWER_MAP_JSON, \"w\") as f: json.dump(reviewer_map, f)\n",
        "    if fitted_asin:\n",
        "        asin_ids = pd.Series(df[\"asin\"].unique())\n",
        "        asin_map = {k: int(v) for v, k in enumerate(asin_ids)}\n",
        "        with open(ASIN_MAP_JSON, \"w\") as f: json.dump(asin_map, f)\n",
        "except Exception as e:\n",
        "    print(f\"Note: Failed saving optional ID maps: {e}\")\n",
        "\n",
        "# Assemble features\n",
        "review_svd_df = pd.DataFrame(review_svd, columns=[f\"review_text_svd_{i}\" for i in range(review_svd.shape[1])])\n",
        "summary_svd_df = pd.DataFrame(summary_svd, columns=[f\"summary_svd_{i}\" for i in range(summary_svd.shape[1])])\n",
        "num_feats = df[[\n",
        "    \"overall\",\"helpful_votes\",\"unhelpful_votes\",\"helpful_unhelpful_ratio\",\n",
        "    \"day_gap\",\"same_day_indicator\",\"review_word_count\",\"sentiment_score\",\n",
        "    \"total_helpful_votes\",\"total_unhelpful_votes\",\"total_votes\"\n",
        "]]\n",
        "\n",
        "X = pd.concat([\n",
        "    num_feats.reset_index(drop=True),\n",
        "    review_svd_df.reset_index(drop=True),\n",
        "    summary_svd_df.reset_index(drop=True),\n",
        "    rev_enc_df.reset_index(drop=True),\n",
        "    asin_enc_df.reset_index(drop=True),\n",
        "    rnm_enc_df.reset_index(drop=True),\n",
        "], axis=1).astype(np.float32)\n",
        "\n",
        "print(\"\\nFeature engineering complete.\")\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 4) Build heterograph: ('r','p','r'), ('r','s','r'), ('r','v','r')\n",
        "# ---------------------------------------------------\n",
        "N = len(df)\n",
        "idx_map = {old: i for i, old in enumerate(df.index)}\n",
        "\n",
        "upu_src, upu_dst = [], []\n",
        "usu_src, usu_dst = [], []\n",
        "uvu_src, uvu_dst = [], []\n",
        "\n",
        "# same product (asin) → 'p'\n",
        "for asin, g_ in df.groupby(\"asin\"):\n",
        "    nodes = [idx_map[i] for i in g_.index.tolist()]\n",
        "    if len(nodes) > 1:\n",
        "        for i in range(len(nodes)):\n",
        "            for j in range(len(nodes)):\n",
        "                if i != j:\n",
        "                    upu_src.append(nodes[i]); upu_dst.append(nodes[j])\n",
        "\n",
        "# same user constraints\n",
        "for uid, g_ in df.groupby(\"reviewerID\"):\n",
        "    rows = g_.index.tolist()\n",
        "    for i in range(len(rows)):\n",
        "        for j in range(len(rows)):\n",
        "            if i == j:\n",
        "                continue\n",
        "            i0, j0 = rows[i], rows[j]\n",
        "            a = idx_map[i0]; b = idx_map[j0]\n",
        "            # U-S-U: same overall rating proxy\n",
        "            if df.loc[i0, \"overall\"] == df.loc[j0, \"overall\"]:\n",
        "                usu_src.append(a); usu_dst.append(b)\n",
        "            # U-V-U: similar review length\n",
        "            if abs(df.loc[i0, \"review_word_count\"] - df.loc[j0, \"review_word_count\"]) <= 10:\n",
        "                uvu_src.append(a); uvu_dst.append(b)\n",
        "\n",
        "# tensors\n",
        "upu_src = torch.tensor(upu_src, dtype=torch.int32)\n",
        "upu_dst = torch.tensor(upu_dst, dtype=torch.int32)\n",
        "usu_src = torch.tensor(usu_src, dtype=torch.int32)\n",
        "usu_dst = torch.tensor(usu_dst, dtype=torch.int32)\n",
        "uvu_src = torch.tensor(uvu_src, dtype=torch.int32)\n",
        "uvu_dst = torch.tensor(uvu_dst, dtype=torch.int32)\n",
        "\n",
        "graph_data = {\n",
        "    (\"r\",\"p\",\"r\"): (upu_src, upu_dst),\n",
        "    (\"r\",\"s\",\"r\"): (usu_src, usu_dst),\n",
        "    (\"r\",\"v\",\"r\"): (uvu_src, uvu_dst),\n",
        "}\n",
        "g = dgl.heterograph(graph_data, num_nodes_dict={\"r\": N})\n",
        "g.nodes[\"r\"].data[\"feat\"] = torch.from_numpy(X.values).float()\n",
        "\n",
        "for et in g.etypes:\n",
        "    g = dgl.add_self_loop(g, etype=et)\n",
        "\n",
        "g = g.to(device)\n",
        "g.nodes[\"r\"].data[\"feat\"] = g.nodes[\"r\"].data[\"feat\"].to(device)\n",
        "\n",
        "# --------------------------------\n",
        "# 5) Model (checkpoint-compatible names)\n",
        "# --------------------------------\n",
        "class RelationAware_Compat(nn.Module):\n",
        "    # ckpt path: rel_aware.d_lin.*\n",
        "    def __init__(self, input_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.d_lin = nn.Linear(input_dim, output_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def forward(self, src, dst):\n",
        "        src = self.d_lin(src)\n",
        "        dst = self.d_lin(dst)\n",
        "        diff = src - dst\n",
        "        return self.tanh(src + dst + diff)\n",
        "\n",
        "class HLayer_Compat(nn.Module):\n",
        "    # ckpt path: blocks.<etype>.[0|1].(...)\n",
        "    def __init__(self, input_dim, output_dim, head, rel_aware, etype, dropout, if_sum=False):\n",
        "        super().__init__()\n",
        "        self.etype = etype\n",
        "        self.head  = head\n",
        "        self.hd    = output_dim\n",
        "        self.if_sum = if_sum\n",
        "\n",
        "        self.atten = nn.Linear(3*output_dim, 1)\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.w_linear = nn.Linear(input_dim, output_dim*head)\n",
        "        self.relation_aware = rel_aware\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.nodes[\"r\"].data[\"feat\"] = h\n",
        "            g.apply_edges(self.sign_edges, etype=self.etype)\n",
        "            h_proj = self.w_linear(h)\n",
        "            g.nodes[\"r\"].data[\"h\"] = h_proj\n",
        "            g.update_all(self.message, self.reduce, etype=self.etype)\n",
        "            out = g.nodes[\"r\"].data[\"out\"]\n",
        "            edge_s = g.nodes[\"r\"].data[\"s\"]\n",
        "            if not self.if_sum:\n",
        "                return edge_s, out, h_proj.view(-1, self.head*self.hd)\n",
        "            else:\n",
        "                return edge_s, out, h_proj.view(-1, self.head, self.hd).sum(-2)\n",
        "\n",
        "    def message(self, edges):\n",
        "        src_f  = edges.src[\"h\"].view(-1, self.head, self.hd)\n",
        "        dst_f  = edges.dst[\"h\"].view(-1, self.head, self.hd)\n",
        "        edge_s = edges.data[\"edge_sum\"].view(-1, self.head, self.hd)\n",
        "        z = torch.cat([src_f, dst_f, edge_s], dim=-1)\n",
        "        alpha = self.atten(z)\n",
        "        alpha = self.leakyrelu(alpha)\n",
        "        return {\"atten\": alpha, \"sf\": src_f, \"edge_s\": edge_s}\n",
        "\n",
        "    def reduce(self, nodes):\n",
        "        alpha = nodes.mailbox[\"atten\"]\n",
        "        sf    = nodes.mailbox[\"sf\"]\n",
        "        alpha = self.softmax(alpha)\n",
        "        out = torch.sum(alpha * sf, dim=1)\n",
        "        if not self.if_sum:\n",
        "            out = out.view(-1, self.head*self.hd)\n",
        "            edge_s = torch.mean(nodes.mailbox[\"edge_s\"], dim=1).view(-1, self.head*self.hd)\n",
        "            return {\"out\": out, \"s\": edge_s}\n",
        "        else:\n",
        "            out = out.sum(dim=-2)\n",
        "            edge_s = torch.sum(torch.mean(nodes.mailbox[\"edge_s\"], dim=1), dim=-2)\n",
        "            return {\"out\": out, \"s\": edge_s}\n",
        "\n",
        "    def sign_edges(self, edges):\n",
        "        src = edges.src[\"feat\"]\n",
        "        dst = edges.dst[\"feat\"]\n",
        "        edge_sum = self.relation_aware(src, dst)\n",
        "        return {\"edge_sum\": edge_sum}\n",
        "\n",
        "class Gate_Compat(nn.Module):\n",
        "    def __init__(self, head, output_dim, dropout, if_sum=False):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.head = head\n",
        "        if not if_sum:\n",
        "            self.beta = nn.Parameter(torch.empty(2*head*output_dim, 1))\n",
        "        else:\n",
        "            self.beta = nn.Parameter(torch.empty(2*output_dim, 1))\n",
        "        nn.init.xavier_normal_(self.beta, gain=1.414)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, edge_sum, out, h):\n",
        "        beta = torch.cat([edge_sum, out], dim=1)\n",
        "        gate = self.sigmoid(beta @ self.beta)\n",
        "        return gate * out + (1 - gate) * h\n",
        "\n",
        "class MultiRelationGELayer_Compat(nn.Module):\n",
        "    # ckpt names: layers.X.lin, layers.X.rel_aware, layers.X.blocks[etype][0/1]\n",
        "    def __init__(self, input_dim, output_dim, head, graph, dropout, if_sum=False):\n",
        "        super().__init__()\n",
        "        rels = list(graph.etypes)\n",
        "        if \"homo\" in rels:\n",
        "            rels.remove(\"homo\")\n",
        "        self.relations = rels\n",
        "        self.if_sum = if_sum\n",
        "\n",
        "        self.rel_aware = RelationAware_Compat(input_dim, output_dim*head, dropout)\n",
        "        if not if_sum:\n",
        "            self.lin = nn.Linear(len(self.relations)*output_dim*head, output_dim*head)\n",
        "        else:\n",
        "            self.lin = nn.Linear(len(self.relations)*output_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.blocks = nn.ModuleDict()\n",
        "        for e in self.relations:\n",
        "            seq = nn.ModuleList()\n",
        "            seq.append(HLayer_Compat(input_dim, output_dim, head, self.rel_aware, e, dropout, if_sum))\n",
        "            seq.append(Gate_Compat(head, output_dim, dropout, if_sum))\n",
        "            self.blocks[e] = seq\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        outs = []\n",
        "        for e, seq in self.blocks.items():\n",
        "            edge_s, out, h_proj = seq[0](g, h)\n",
        "            he = seq[1](edge_s, out, h_proj)\n",
        "            outs.append(he)\n",
        "        x = torch.cat(outs, dim=1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin(x)\n",
        "        return x\n",
        "\n",
        "class GE_GNN_Compat(nn.Module):\n",
        "    # top-level ckpt list name: layers\n",
        "    def __init__(self, args, g):\n",
        "        super().__init__()\n",
        "        if \"r\" in g.ntypes and \"feat\" in g.nodes[\"r\"].data:\n",
        "            in_dim = g.nodes[\"r\"].data[\"feat\"].shape[1]\n",
        "        elif \"feature\" in g.ndata:\n",
        "            in_dim = g.ndata[\"feature\"].shape[1]\n",
        "        else:\n",
        "            raise RuntimeError(\"No node features found ('feat' or 'feature').\")\n",
        "        self.layers = nn.ModuleList()\n",
        "        if args.n_layer == 1:\n",
        "            self.layers.append(MultiRelationGELayer_Compat(in_dim, args.n_class, args.head, g, args.dropout, if_sum=True))\n",
        "        else:\n",
        "            self.layers.append(MultiRelationGELayer_Compat(in_dim, args.intra_dim, args.head, g, args.dropout, if_sum=False))\n",
        "            for _ in range(1, args.n_layer-1):\n",
        "                self.layers.append(MultiRelationGELayer_Compat(args.intra_dim*args.head, args.intra_dim, args.head, g, args.dropout, if_sum=False))\n",
        "            self.layers.append(MultiRelationGELayer_Compat(args.intra_dim*args.head, args.n_class, args.head, g, args.dropout, if_sum=True))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(args.dropout)\n",
        "\n",
        "    def forward(self, g):\n",
        "        if \"r\" in g.ntypes and \"feat\" in g.nodes[\"r\"].data:\n",
        "            h = g.nodes[\"r\"].data[\"feat\"].float()\n",
        "        elif \"feature\" in g.ndata:\n",
        "            h = g.ndata[\"feature\"].float()\n",
        "        else:\n",
        "            raise RuntimeError(\"Missing features for forward.\")\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            h = layer(g, h)\n",
        "            if i < len(self.layers) - 1:\n",
        "                h = self.relu(h)\n",
        "                h = self.drop(h)\n",
        "        return h\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 6) Load model & run\n",
        "# ---------------------------------------------------\n",
        "print(\"\\n--- Loading model ---\")\n",
        "model = GE_GNN_Compat(args, g).to(device)\n",
        "state = torch.load(MODEL_PATH, map_location=device)\n",
        "missing, unexpected = model.load_state_dict(state, strict=False)\n",
        "if missing or unexpected:\n",
        "    print(\"Note: non-strict load due to mismatches.\")\n",
        "    if missing:   print(\"  Missing keys:\", missing)\n",
        "    if unexpected:print(\"  Unexpected keys:\", unexpected)\n",
        "else:\n",
        "    print(\"Model loaded successfully (strict=True would have worked).\")\n",
        "\n",
        "model.eval()\n",
        "print(\"Model ready.\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(g)                     # (N, n_class)\n",
        "    probs  = F.softmax(logits, dim=1)     # (N, n_class)\n",
        "    fraud_prob = probs[:,1].detach().cpu().numpy()\n",
        "    pred_cls   = logits.argmax(1).detach().cpu().numpy()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 7) Export + optional metrics\n",
        "# ---------------------------------------------------\n",
        "df_out = df_orig.copy()\n",
        "df_out['predicted_fraud_class'] = pred_cls\n",
        "df_out['fraud_probability']     = fraud_prob\n",
        "\n",
        "print(\"\\nSample predictions:\")\n",
        "cols_show = ['reviewerID','asin','overall','predicted_fraud_class','fraud_probability']\n",
        "if 'class' in df_out.columns:\n",
        "    cols_show.append('class')\n",
        "print(df_out[cols_show].head(10))\n",
        "\n",
        "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "OUT_CSV = os.path.join(OUT_DIR, f\"inference_predictions_{stamp}.csv\")\n",
        "df_out.to_csv(OUT_CSV, index=False)\n",
        "print(f\"\\n✅ Inference complete. Predictions saved to:\\n{OUT_CSV}\")\n",
        "\n",
        "# Metrics if ground-truth is available\n",
        "if 'class' in df_out.columns:\n",
        "    y_true = df_out['class'].astype(int).values\n",
        "    y_pred = df_out['predicted_fraud_class'].astype(int).values\n",
        "    y_prob = df_out['fraud_probability'].astype(float).values\n",
        "\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    try:\n",
        "        auc  = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else 0.5\n",
        "    except ValueError:\n",
        "        auc = 0.5\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "    gmean = float(np.sqrt(tpr*tnr)) if tpr>0 and tnr>0 else 0.0\n",
        "\n",
        "    print(\"\\n================= MODEL EVALUATION =================\")\n",
        "    print(f\"Accuracy:      {acc:.4f}\")\n",
        "    print(f\"Precision:     {prec:.4f}\")\n",
        "    print(f\"Recall:        {rec:.4f}\")\n",
        "    print(f\"F1 Score:      {f1:.4f}\")\n",
        "    print(f\"AUC:           {auc:.4f}\")\n",
        "    print(f\"G-Mean:        {gmean:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "else:\n",
        "    print(\"\\n(No 'class' column found — skipped metrics.)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaPn39U8Ie4v",
        "outputId": "68447fc8-74f8-4481-e6a6-aa465f718e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Using device: cuda:0\n",
            "\n",
            "--- Loading new data for inference ---\n",
            "Loaded 500 rows from:\n",
            "/content/drive/MyDrive/GE-GNN/MY_work/DataSets/sports_test_inference.csv\n",
            "\n",
            "--- Loading/Fitting text/vector encoders ---\n",
            "\n",
            "--- Loading/Fitting categorical encoders ---\n",
            "\n",
            "Feature engineering complete.\n",
            "Feature matrix shape: (500, 24)\n",
            "\n",
            "--- Loading model ---\n",
            "Model loaded successfully (strict=True would have worked).\n",
            "Model ready.\n",
            "\n",
            "Sample predictions:\n",
            "       reviewerID        asin  overall  predicted_fraud_class  \\\n",
            "0  A140N2G9RBBP4R  B00176T9OY      3.0                      1   \n",
            "1   AMWFW5H88D9KC  B004HKICCW      5.0                      0   \n",
            "2   A778RZMTRYBVQ  B005CU6GBU      3.0                      0   \n",
            "3  A323TVT239WQG3  B009FMNFYC      4.0                      0   \n",
            "4  A1KULI5HW8BVMH  B00AZPWV7K      5.0                      0   \n",
            "5  A1DKVLJ1E91FMX  B00CHKL7EE      1.0                      1   \n",
            "6   AMMCJ1AA1FWHV  B006IXB73C      3.0                      0   \n",
            "7   AE8WJT1P21Y39  B00CSZK708      4.0                      0   \n",
            "8  A3SYWN34IVBN08  B002AQHM3U      5.0                      1   \n",
            "9   AAINFA1I7INLL  B0068FAQIM      2.0                      1   \n",
            "\n",
            "   fraud_probability  class  \n",
            "0       1.000000e+00    0.0  \n",
            "1       2.539939e-08    1.0  \n",
            "2       1.466615e-08    0.0  \n",
            "3       2.956870e-11    1.0  \n",
            "4       1.551840e-08    1.0  \n",
            "5       1.000000e+00    0.0  \n",
            "6       8.088985e-08    0.0  \n",
            "7       2.760944e-01    1.0  \n",
            "8       1.000000e+00    1.0  \n",
            "9       1.000000e+00    0.0  \n",
            "\n",
            "✅ Inference complete. Predictions saved to:\n",
            "/content/drive/MyDrive/GE-GNN/result/inference_predictions_20251109_102546.csv\n",
            "\n",
            "================= MODEL EVALUATION =================\n",
            "Accuracy:      0.5240\n",
            "Precision:     0.5181\n",
            "Recall:        0.6880\n",
            "F1 Score:      0.5911\n",
            "AUC:           0.5365\n",
            "G-Mean:        0.4977\n",
            "Confusion Matrix:\n",
            "[[ 90 160]\n",
            " [ 78 172]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# Ensure the CSV has true labels\n",
        "# ------------------------------\n",
        "if \"class\" not in df_out.columns: # Changed 'label' to 'class'\n",
        "    raise RuntimeError(\"Your CSV must contain a 'class' column with 0/1 ground truth.\")\n",
        "\n",
        "y_true = df_out[\"class\"].astype(int).values # Changed 'label' to 'class'\n",
        "y_pred = df_out[\"predicted_fraud_class\"].astype(int).values\n",
        "y_prob = df_out[\"fraud_probability\"].astype(float).values\n",
        "\n",
        "# Basic metrics\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "# AUC (must pass probabilities)\n",
        "try:\n",
        "    auc  = roc_auc_score(y_true, y_prob)\n",
        "except ValueError:\n",
        "    auc = 0.0  # if only one class present\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# G-Mean like your training code\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "gmean = np.sqrt(tpr * tnr)\n",
        "\n",
        "print(\"\\n================= MODEL EVALUATION =================\")\n",
        "print(f\"Accuracy:      {acc:.4f}\")\n",
        "print(f\"Precision:     {prec:.4f}\")\n",
        "print(f\"Recall:        {rec:.4f}\")\n",
        "print(f\"F1 Score:      {f1:.4f}\")\n",
        "print(f\"AUC:           {auc:.4f}\")\n",
        "print(f\"G-Mean:        {gmean:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"====================================================\\n\")\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Print details for predicted fraud and non-fraud reviews\n",
        "# ----------------------------------------------------\n",
        "print(\"\\n--- Predicted Fraud Reviews (First 5) ---\")\n",
        "predicted_fraud_df = df_out[df_out['predicted_fraud_class'] == 1]\n",
        "display(predicted_fraud_df.head())\n",
        "\n",
        "print(\"\\n--- Predicted Non-Fraud Reviews (First 5) ---\")\n",
        "predicted_non_fraud_df = df_out[df_out['predicted_fraud_class'] == 0]\n",
        "display(predicted_non_fraud_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6wK8CXUo4iFW",
        "outputId": "7fd96774-454c-49af-ffa3-3e03e5a87a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================= MODEL EVALUATION =================\n",
            "Accuracy:      0.5240\n",
            "Precision:     0.5181\n",
            "Recall:        0.6880\n",
            "F1 Score:      0.5911\n",
            "AUC:           0.5365\n",
            "G-Mean:        0.4977\n",
            "Confusion Matrix:\n",
            "[[ 90 160]\n",
            " [ 78 172]]\n",
            "====================================================\n",
            "\n",
            "\n",
            "--- Predicted Fraud Reviews (First 5) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                     _id      reviewerID        asin  \\\n",
              "0   {'$oid': '5a132792741a2384e855ebe7'}  A140N2G9RBBP4R  B00176T9OY   \n",
              "5   {'$oid': '5a1327f5741a2384e876bf7c'}  A1DKVLJ1E91FMX  B00CHKL7EE   \n",
              "8   {'$oid': '5a1327a8741a2384e85d2e7b'}  A3SYWN34IVBN08  B002AQHM3U   \n",
              "9   {'$oid': '5a1327db741a2384e86dc9d8'}   AAINFA1I7INLL  B0068FAQIM   \n",
              "10  {'$oid': '5a1327f3741a2384e8763123'}   A9Q28YTLYREO7  B00BRBC8F6   \n",
              "\n",
              "                     reviewerName    helpful  \\\n",
              "0                              na     [0, 0]   \n",
              "5              Pike \"Pike Hunter\"     [0, 0]   \n",
              "8                  Terminal Guard  [96, 103]   \n",
              "9                        scisskid     [0, 0]   \n",
              "10  mistermaxxx08 \"mistermaxxx08\"     [0, 0]   \n",
              "\n",
              "                                           reviewText  overall  \\\n",
              "0   This radio was ordered to provide notification...      3.0   \n",
              "5            Sending them back. These are 6.5 inches.      1.0   \n",
              "8   Let me first say that nothing can replace the ...      5.0   \n",
              "9   Tube blew in my face at 35 psi while inflating...      2.0   \n",
              "10  always dug Jesus  Shuttleworth  from back in t...      5.0   \n",
              "\n",
              "                        summary  unixReviewTime   reviewTime  \\\n",
              "0                 Midland Radio      1376870400  08 19, 2013   \n",
              "5                Caveat emptor!      1404950400  07 10, 2014   \n",
              "8                Paint it Black      1249516800   08 6, 2009   \n",
              "9   Good seller, terrible tube.      1405036800  07 11, 2014   \n",
              "10          great clutch player      1388707200   01 3, 2014   \n",
              "\n",
              "               category  class  predicted_fraud_class  fraud_probability  \n",
              "0   Sports_and_Outdoors    0.0                      1                1.0  \n",
              "5   Sports_and_Outdoors    0.0                      1                1.0  \n",
              "8   Sports_and_Outdoors    1.0                      1                1.0  \n",
              "9   Sports_and_Outdoors    0.0                      1                1.0  \n",
              "10  Sports_and_Outdoors    1.0                      1                1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69df8726-c612-46c9-b3ea-7ecdd8cac39c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>category</th>\n",
              "      <th>class</th>\n",
              "      <th>predicted_fraud_class</th>\n",
              "      <th>fraud_probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'$oid': '5a132792741a2384e855ebe7'}</td>\n",
              "      <td>A140N2G9RBBP4R</td>\n",
              "      <td>B00176T9OY</td>\n",
              "      <td>na</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>This radio was ordered to provide notification...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Midland Radio</td>\n",
              "      <td>1376870400</td>\n",
              "      <td>08 19, 2013</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'$oid': '5a1327f5741a2384e876bf7c'}</td>\n",
              "      <td>A1DKVLJ1E91FMX</td>\n",
              "      <td>B00CHKL7EE</td>\n",
              "      <td>Pike \"Pike Hunter\"</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Sending them back. These are 6.5 inches.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Caveat emptor!</td>\n",
              "      <td>1404950400</td>\n",
              "      <td>07 10, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'$oid': '5a1327a8741a2384e85d2e7b'}</td>\n",
              "      <td>A3SYWN34IVBN08</td>\n",
              "      <td>B002AQHM3U</td>\n",
              "      <td>Terminal Guard</td>\n",
              "      <td>[96, 103]</td>\n",
              "      <td>Let me first say that nothing can replace the ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Paint it Black</td>\n",
              "      <td>1249516800</td>\n",
              "      <td>08 6, 2009</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'$oid': '5a1327db741a2384e86dc9d8'}</td>\n",
              "      <td>AAINFA1I7INLL</td>\n",
              "      <td>B0068FAQIM</td>\n",
              "      <td>scisskid</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Tube blew in my face at 35 psi while inflating...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Good seller, terrible tube.</td>\n",
              "      <td>1405036800</td>\n",
              "      <td>07 11, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'$oid': '5a1327f3741a2384e8763123'}</td>\n",
              "      <td>A9Q28YTLYREO7</td>\n",
              "      <td>B00BRBC8F6</td>\n",
              "      <td>mistermaxxx08 \"mistermaxxx08\"</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>always dug Jesus  Shuttleworth  from back in t...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>great clutch player</td>\n",
              "      <td>1388707200</td>\n",
              "      <td>01 3, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69df8726-c612-46c9-b3ea-7ecdd8cac39c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69df8726-c612-46c9-b3ea-7ecdd8cac39c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69df8726-c612-46c9-b3ea-7ecdd8cac39c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f45139d-18ba-4662-b613-99f5f4a6510d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f45139d-18ba-4662-b613-99f5f4a6510d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f45139d-18ba-4662-b613-99f5f4a6510d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(predicted_non_fraud_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"{'$oid': '5a1327f5741a2384e876bf7c'}\",\n          \"{'$oid': '5a1327f3741a2384e8763123'}\",\n          \"{'$oid': '5a1327a8741a2384e85d2e7b'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewerID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A1DKVLJ1E91FMX\",\n          \"A9Q28YTLYREO7\",\n          \"A3SYWN34IVBN08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"B00CHKL7EE\",\n          \"B00BRBC8F6\",\n          \"B002AQHM3U\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewerName\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Pike \\\"Pike Hunter\\\"\",\n          \"mistermaxxx08 \\\"mistermaxxx08\\\"\",\n          \"Terminal Guard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"helpful\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[96, 103]\",\n          \"[0, 0]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sending them back. These are 6.5 inches.\",\n          \"always dug Jesus  Shuttleworth  from back in the day and  he is one of  the Greatest Shooters  Ever in the League period. game 6 in the finals game tying  3 pointer will always be remembered forever.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7888543819998317,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Caveat emptor!\",\n          \"great clutch player\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unixReviewTime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65647326,\n        \"min\": 1249516800,\n        \"max\": 1405036800,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1404950400,\n          1388707200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewTime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"07 10, 2014\",\n          \"01 3, 2014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Sports_and_Outdoors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_fraud_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fraud_probability\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Predicted Non-Fraud Reviews (First 5) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                    _id      reviewerID        asin  \\\n",
              "1  {'$oid': '5a1327c7741a2384e867945d'}   AMWFW5H88D9KC  B004HKICCW   \n",
              "2  {'$oid': '5a1327d3741a2384e86b7575'}   A778RZMTRYBVQ  B005CU6GBU   \n",
              "3  {'$oid': '5a1327ec741a2384e8737ef0'}  A323TVT239WQG3  B009FMNFYC   \n",
              "4  {'$oid': '5a1327f1741a2384e8753e64'}  A1KULI5HW8BVMH  B00AZPWV7K   \n",
              "6  {'$oid': '5a1327dc741a2384e86e292a'}   AMMCJ1AA1FWHV  B006IXB73C   \n",
              "\n",
              "                reviewerName helpful  \\\n",
              "1                       Eric  [0, 0]   \n",
              "2  BENMESSAOUD \"Fishing Fan\"  [0, 0]   \n",
              "3                  tacitworm  [0, 0]   \n",
              "4                     Daniel  [0, 0]   \n",
              "6                JamesTRabon  [0, 0]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "1  This light far exceeded my expectations. It ho...      5.0   \n",
              "2  I bought the hook remover since 3 months but o...      3.0   \n",
              "3  Great for massage therapy.  Strong odor of rub...      4.0   \n",
              "4  I use this for a dual function, first my wife ...      5.0   \n",
              "6  The paddles are extremely cheap on a windy day...      3.0   \n",
              "\n",
              "                                summary  unixReviewTime   reviewTime  \\\n",
              "1          Long Lasting and Very Bright      1361664000  02 24, 2013   \n",
              "2  Good but not necessarily easy to use      1396656000   04 5, 2014   \n",
              "3                  Joe's Lacrosse Balls      1389916800  01 17, 2014   \n",
              "4                         Daul function      1399939200  05 13, 2014   \n",
              "6                                    Ok      1397692800  04 17, 2014   \n",
              "\n",
              "              category  class  predicted_fraud_class  fraud_probability  \n",
              "1  Sports_and_Outdoors    1.0                      0       2.539939e-08  \n",
              "2  Sports_and_Outdoors    0.0                      0       1.466615e-08  \n",
              "3  Sports_and_Outdoors    1.0                      0       2.956870e-11  \n",
              "4  Sports_and_Outdoors    1.0                      0       1.551840e-08  \n",
              "6  Sports_and_Outdoors    0.0                      0       8.088985e-08  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4f0d6ed-7542-4235-8cc9-5b4e9310dd86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>category</th>\n",
              "      <th>class</th>\n",
              "      <th>predicted_fraud_class</th>\n",
              "      <th>fraud_probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'$oid': '5a1327c7741a2384e867945d'}</td>\n",
              "      <td>AMWFW5H88D9KC</td>\n",
              "      <td>B004HKICCW</td>\n",
              "      <td>Eric</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>This light far exceeded my expectations. It ho...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Long Lasting and Very Bright</td>\n",
              "      <td>1361664000</td>\n",
              "      <td>02 24, 2013</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.539939e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'$oid': '5a1327d3741a2384e86b7575'}</td>\n",
              "      <td>A778RZMTRYBVQ</td>\n",
              "      <td>B005CU6GBU</td>\n",
              "      <td>BENMESSAOUD \"Fishing Fan\"</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I bought the hook remover since 3 months but o...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Good but not necessarily easy to use</td>\n",
              "      <td>1396656000</td>\n",
              "      <td>04 5, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.466615e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'$oid': '5a1327ec741a2384e8737ef0'}</td>\n",
              "      <td>A323TVT239WQG3</td>\n",
              "      <td>B009FMNFYC</td>\n",
              "      <td>tacitworm</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>Great for massage therapy.  Strong odor of rub...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Joe's Lacrosse Balls</td>\n",
              "      <td>1389916800</td>\n",
              "      <td>01 17, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.956870e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'$oid': '5a1327f1741a2384e8753e64'}</td>\n",
              "      <td>A1KULI5HW8BVMH</td>\n",
              "      <td>B00AZPWV7K</td>\n",
              "      <td>Daniel</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>I use this for a dual function, first my wife ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Daul function</td>\n",
              "      <td>1399939200</td>\n",
              "      <td>05 13, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.551840e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'$oid': '5a1327dc741a2384e86e292a'}</td>\n",
              "      <td>AMMCJ1AA1FWHV</td>\n",
              "      <td>B006IXB73C</td>\n",
              "      <td>JamesTRabon</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>The paddles are extremely cheap on a windy day...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Ok</td>\n",
              "      <td>1397692800</td>\n",
              "      <td>04 17, 2014</td>\n",
              "      <td>Sports_and_Outdoors</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.088985e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4f0d6ed-7542-4235-8cc9-5b4e9310dd86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4f0d6ed-7542-4235-8cc9-5b4e9310dd86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4f0d6ed-7542-4235-8cc9-5b4e9310dd86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e2e7d2c0-3f97-4196-a5a7-4c4a04d36949\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2e7d2c0-3f97-4196-a5a7-4c4a04d36949')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e2e7d2c0-3f97-4196-a5a7-4c4a04d36949 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}